import streamlit as st
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np
import fitz  # PyMuPDF
import pandas as pd
import io

import os

UPLOAD_DIR = "uploaded_files"
os.makedirs(UPLOAD_DIR, exist_ok=True)

st.set_page_config(page_title="Similarit√© Cosinus - Fichiers", layout="wide")
st.title("üìÅ Analyse de similarit√© entre une requ√™te et des fichiers")

# Choix du mod√®le
model_choice = st.selectbox(
    "üß† Choisissez un mod√®le d'embedding",
    [
        "all-MiniLM-L6-v2",
        "all-mpnet-base-v2",
        "paraphrase-MiniLM-L6-v2",
        "multi-qa-MiniLM-L6-cos-v1",
    ],
)

# Entr√©e de la requ√™te
query_text = st.text_input(
    "üîç Requ√™te (texte ou question)", "l‚Äôintelligence artificielle dans l‚Äô√©ducation"
)

# Upload de fichiers
uploaded_files = st.file_uploader(
    "üìÇ Chargez vos fichiers (.txt ou .pdf)",
    type=["txt", "pdf"],
    accept_multiple_files=True,
)

# Enregistrement local des fichiers upload√©s
# for file in uploaded_files:
#     save_path = os.path.join(UPLOAD_DIR, file.name)
#     with open(save_path, "wb") as f:
#         f.write(file.read())

# Seuil
threshold = st.slider("üéöÔ∏è Seuil de similarit√© minimale", 0.0, 1.0, 0.3, step=0.05)


# Fonction d‚Äôextraction texte
def extract_text(file):
    if file.type == "text/plain":
        return file.read().decode("utf-8", errors="ignore")
    elif file.type == "application/pdf":
        text = ""
        with fitz.open(stream=file.read(), filetype="pdf") as doc:
            for page in doc:
                text += page.get_text()
        return text
    return ""


# Bouton de traitement
if st.button("üß† Analyser les similarit√©s") and uploaded_files:
    with st.spinner("Encodage et calcul des similarit√©s..."):
        model = SentenceTransformer(model_choice)
        query_vec = model.encode([query_text])

        file_texts = []
        file_names = []
        for file in uploaded_files:
            content = extract_text(file)
            if content.strip():
                file_texts.append(content)
                file_names.append(file.name)

        if not file_texts:
            st.warning("Aucun texte lisible extrait des fichiers.")
        else:
            file_vecs = model.encode(file_texts)
            sims = cosine_similarity(file_vecs, query_vec).flatten()

            ranked = sorted(
                zip(file_names, file_texts, sims, file_vecs),
                key=lambda x: x[2],
                reverse=True,
            )
            filtered = [
                (name, text, sim, vec)
                for name, text, sim, vec in ranked
                if sim >= threshold
            ]

            if not filtered:
                st.warning("Aucun fichier ne d√©passe le seuil.")
            else:
                # Projection PCA
                names, texts, sims_filtered, vecs_filtered = zip(*filtered)
                reduced = PCA(n_components=2).fit_transform(
                    np.vstack([query_vec, vecs_filtered])
                )
                query_2d, docs_2d = reduced[0], reduced[1:]

                fig, ax = plt.subplots(figsize=(9, 6))
                ax.scatter(docs_2d[:, 0], docs_2d[:, 1], c="blue", label="Fichiers")
                ax.scatter(
                    query_2d[0],
                    query_2d[1],
                    c="red",
                    marker="X",
                    s=100,
                    label="Requ√™te",
                )

                for i, (x, y) in enumerate(docs_2d):
                    ax.text(x + 0.01, y + 0.01, f"{sims_filtered[i]:.2f}", fontsize=9)
                    ax.text(x + 0.01, y - 0.04, f"{i + 1}. {names[i][:20]}", fontsize=8)

                ax.set_title("Projection PCA 2D - Requ√™te vs Fichiers")
                ax.set_xlabel("PCA 1")
                ax.set_ylabel("PCA 2")
                ax.grid(True)
                ax.legend()
                st.pyplot(fig)

                st.markdown("### üìä R√©sultats tri√©s (fichiers au-dessus du seuil)")

                results = []
                for i, (name, sim, text) in enumerate(
                    zip(names, sims_filtered, texts), 1
                ):
                    st.markdown(f"**{i}. `{name}`** ‚Äì Similarit√© : `{sim:.4f}`")
                    st.markdown(f"> _Extrait_ : {text.strip()[:300]}‚Ä¶")
                    results.append(
                        {
                            "Rang": i,
                            "Nom du fichier": name,
                            "Similarit√©": round(sim, 4),
                            "Extrait": text.strip()[:500],
                        }
                    )

                # Export CSV
                df = pd.DataFrame(results)
                csv_buffer = io.StringIO()
                df.to_csv(csv_buffer, index=False)
                csv_data = csv_buffer.getvalue().encode("utf-8")

                st.download_button(
                    label="üì• T√©l√©charger les r√©sultats en CSV",
                    data=csv_data,
                    file_name="resultats_similarite.csv",
                    mime="text/csv",
                )
